{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xBkcmAQfBysNmBNLZpfgdT5QFzJrtnbn","timestamp":1671460537388},{"file_id":"1OWUMfQHbAVwS1FwSXpZeAo9N5COiMgQ0","timestamp":1670269584728},{"file_id":"18gebSsY-hhzVA9PJXFuq2UIJo7it9jgq","timestamp":1669654719837}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# WikiNER Project\n","\n","### Abdullah Aljbab\n","### Adele Haghighat Hoseini\n","### Fulayjan Alanazi "],"metadata":{"id":"cxvf1zreKLc7"}},{"cell_type":"code","source":["#@title Requirements\n","!pip install -r requirements.txt\n","# !pip install torch\n","# !pip install numpy==1.16.0\n","# !pip install mxnet-cu92\n","# !pip install mxnet\n","# !pip install TensorFlow\n","# !pip install bert-embedding\n","# !pip install transformers\n","# !pip install tqdm\n","# !pip install pandas\n","# !pip install itertools\n","# !pip install operator\n","# !pip install sklearn.metrics\n","# !pip install nltk\n","# !pip install argparse\n","# !pip install spacy\n","# !pip install zmq\n","# !pip install contextlib\n","# !pip install pathlib\n","# !pip install re\n","# !pip install subprocess\n","# !pip install ast"],"metadata":{"id":"2h9pjPzQbDEG","executionInfo":{"status":"ok","timestamp":1671466603425,"user_tz":360,"elapsed":626,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["#@title Importing Libraries\n","import json\n","import csv\n","import urllib.request\n","from tqdm import tqdm\n","import pandas as pd\n","import itertools\n","from operator import itemgetter\n","from sklearn import metrics \n","from sklearn.metrics import f1_score\n","import nltk\n","import os\n","import argparse\n","import time\n","\n","import numpy as np\n","import torch\n","from transformers import BertTokenizerFast, BertForTokenClassification\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD\n","# from bert_embedding import BertEmbedding\n","\n","from transformers import BertTokenizer\n","from transformers import BertModel\n","\n","import spacy\n","import torch\n","from transformers import BertModel\n","\n","# from zmq.constants import NULL\n","# from contextlib import nullcontext\n","\n","from pathlib import Path\n","import re"],"metadata":{"id":"Dn2C3zPBdvS3","executionInfo":{"status":"ok","timestamp":1671466603426,"user_tz":360,"elapsed":4,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["#@title Process\n","import subprocess\n","from ast import literal_eval\n","\n","def run(command):\n","    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n","    out, err = process.communicate()\n","    print(out.decode('utf-8').strip())\n","\n","print('# CPU')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n","\n","print('# RAM')\n","run('cat /proc/meminfo | egrep \"^MemTotal\"')\n","\n","print('# GPU')\n","run('lspci | grep VGA')\n","\n","print('# OS')\n","run('uname -a')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXmK8OFiGMhy","executionInfo":{"status":"ok","timestamp":1671466603841,"user_tz":360,"elapsed":418,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"outputId":"252bf5e8-9c82-4236-d62d-6e6695c03be1","cellView":"form"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["# CPU\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","cpu MHz\t\t: 2199.998\n","cpu cores\t: 2\n","# RAM\n","MemTotal:       26690640 kB\n","# GPU\n","\n","# OS\n","Linux fe94ba42868e 5.10.133+ #1 SMP Fri Aug 26 08:44:51 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux\n"]}]},{"cell_type":"code","source":["#@title Variables\n","\n","!wget https://qrank.wmcloud.org/download/qrank.csv.gz\n","!gunzip qrank.csv.gz\n","\n","input_csv_path = 'qrank.csv'\n","output_csv_path = 'output.csv'\n","\n","CoNLL_train='train.txt'\n","CoNLL_valid='valid.txt'\n","CoNLL_test='test.txt'\n","\n","model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True,)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"metadata":{"id":"ghrfxKzGhRG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Reading CSV\n","def ReadingCSV(iPath,iterations):\n","  Qn=[]\n","  Qr=[]\n","  with open(iPath, newline='') as csvfile:\n","    data = csv.reader(csvfile)\n","    for row in itertools.islice(data,1,iterations+1):\n","      Qn.append(row[0])\n","      Qr.append(row[1])\n","  return Qn,Qr"],"metadata":{"id":"GbRe2HzWrZb-","executionInfo":{"status":"ok","timestamp":1671466607617,"user_tz":360,"elapsed":4,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":34,"outputs":[]},{"cell_type":"code","execution_count":35,"metadata":{"id":"VxUiQL7ccKtd","executionInfo":{"status":"ok","timestamp":1671466607617,"user_tz":360,"elapsed":3,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"outputs":[],"source":["#@title wiki API: Reutrning List\n","def wikiAPI(Qn,iterations):\n","  lis=[]\n","  for i in range(iterations):\n","    x=urllib.request.urlopen('https://www.wikidata.org/w/api.php?action=wbgetentities&props=labels&ids='+Qn[i]+'&languages=en&format=json')\n","    y=json.loads(x.read())\n","    lis.append(y['entities'][Qn[i]]['labels']['en']['value'])\n","\n","  return lis"]},{"cell_type":"code","source":["#@title BIO\n","\n","def BIO(file_path):\n","    file_path = Path(file_path)\n","\n","    raw_text = file_path.read_text().strip()\n","    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n","    token_docs = []\n","    tag_docs = []\n","    lable_docs =[]\n","    for doc in raw_docs:\n","        tokens = []\n","        tags = []\n","        lables=[]\n","        for i,(line) in enumerate(doc.split('\\n')):\n","          x=line.split()\n","          tokens.append(x[0])\n","          tags.append(x[3][:1])\n","          lables.append(x[3])\n","        token_docs.append(tokens)\n","        tag_docs.append(tags)\n","        lable_docs.append(lables)\n","\n","    return token_docs, tag_docs, lable_docs"],"metadata":{"id":"jnj1tIuBNrS8","executionInfo":{"status":"ok","timestamp":1671466607618,"user_tz":360,"elapsed":4,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["#@title Exporting Results: ToOutput\n","def ToOutput(fileName,Col1,Col2,Col3,iterations):\n","\n","  i=1\n","  with open(fileName, 'w', encoding=\"UTF-8\") as csvfile:\n","    fieldnames = ['Qnumber','Qrank','Lable']\n","    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","    writer.writeheader()\n","    for i in range (iterations):\n","      writer.writerow({'Qnumber':Col1[i],  'Qrank':Col2[i], 'Lable':Col3[i]})\n","      i+=1"],"metadata":{"id":"ApndHPbzOQN9","executionInfo":{"status":"ok","timestamp":1671466607618,"user_tz":360,"elapsed":4,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["#@title Test on CoNLL\n","def test_on_CoNLL(sentences, ground_truth_tag_sequences, NE_list, scheme=\"BIO\"):\n","  performance_score = 0 \n","  for sen,gt in zip(sentences,ground_truth_tag_sequences):\n","\n","      tag_seq = brutal_force_NER(sen, NE_list, scheme=scheme) #predicted_tag_seq)\n","      performance_score += a_judge_function(tag_seq, gt) #ground_truth_tag_sequences\n","\n","  return performance_score/len(sentences)"],"metadata":{"id":"rgUgUONIlfob","executionInfo":{"status":"ok","timestamp":1671466607618,"user_tz":360,"elapsed":4,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["#@title Brutal Force NER: Constructing [B-I-O]\n","\n","# from zmq.constants import NULL\n","# from contextlib import nullcontext\n","\n","def brutal_force_NER(sentence, NE_list, scheme=\"BIO\"):\n","\n","    for NE in NE_list:\n","            pattern = ''\n","            position = sentence.find(NE)\n","            \n","            if position > -1: \n","                for index, conx in enumerate(NE.split()): \n","                    if index == 0:\n","                        pattern += 'B'\n","                    else:\n","                        pattern += ' @I'              \n","                sentence = sentence.replace(NE, pattern)\n","            else:\n","                pass          \n","    GTT = []\n","    for i in sentence.split():\n","        if i not in ['B', '@I', 'O']:\n","            GTT.append('O')\n","        else:\n","            if i == '@I':\n","                GTT.append('I')\n","            else:\n","                GTT.append(i)\n","    return GTT"],"metadata":{"id":"dM6G-z9xXGzo","executionInfo":{"status":"ok","timestamp":1671466607618,"user_tz":360,"elapsed":4,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["#@title Judge Function: Returning F1 score\n","def a_judge_function(predicted_tag_seq, grouth_truth_tag_seq):\n","\n","    score = f1_score(grouth_truth_tag_seq, predicted_tag_seq,average=\"weighted\")\n","\n","    return score "],"metadata":{"id":"swddAQAXXVu2","executionInfo":{"status":"ok","timestamp":1671466607618,"user_tz":360,"elapsed":4,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["#@title Get Contextual Embeddings\n","def get_contextual_embeddings(tokens):\n","  # Load the BERT model\n","  model = BertModel.from_pretrained('bert-base-uncased')\n","  # Put the model in evalutation mode\n","  model.eval()\n","  \n","  # Convert the tokens to torch tensors\n","  tokens_tensor = torch.tensor([tokens])\n","  \n","  # Obtain the contextual embeddings for the tokens\n","  with torch.no_grad():\n","    outputs = model(tokens_tensor)\n","    embeddings = outputs[0]\n","\n","  return embeddings"],"metadata":{"id":"aJ_RawHdxtp2","executionInfo":{"status":"ok","timestamp":1671466607619,"user_tz":360,"elapsed":5,"user":{"displayName":"Abdullah Aljbab","userId":"10000559540798101030"}},"cellView":"form"},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["#@title Main\n","loop_N = [100,1000,1500] # we could not run it with more than 2000\n","if __name__ == '__main__':\n","  for i in range(len(loop_N)):\n","      start = time.time()\n","\n","      top_N=loop_N[i]\n","      Qnumber,Qrank=ReadingCSV(input_csv_path,top_N)\n","\n","      Wiki_NE_List = wikiAPI(Qnumber, top_N)\n","\n","      Sents, GTTS,lables = BIO(CoNLL_train)\n","      new_word=[]\n","      for i,(words) in enumerate(Sents):\n","        sentence = ' '.join(words)\n","        new_word.extend([sentence])\n","      Sents=new_word\n","\n","      ToOutput(output_csv_path,Qnumber,Qrank,Wiki_NE_List,top_N)\n","      print ('Befor sorting: ',len(Wiki_NE_List),' of Wiki_NE_List')\n","      CoNLL= test_on_CoNLL(Sents,GTTS,Wiki_NE_List)\n","      print('Score:',\"{:.2%}\".format(CoNLL))\n","      \n","      Wiki_NE_List.sort(key=len, reverse=True)\n","      print ('\\nAfter sorting: ',len(Wiki_NE_List),' of Wiki_NE_List')\n","      CoNLL= test_on_CoNLL(Sents,GTTS,Wiki_NE_List)\n","      print('Score:',\"{:.2%}\".format(CoNLL))\n","\n","      elapsed_time = time.time() - start\n","      print('\\nExecution time:', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n","      print('------------------------------------------------\\n')      "],"metadata":{"id":"5zoB-LlzcTg2","cellView":"form"},"execution_count":null,"outputs":[]}]}